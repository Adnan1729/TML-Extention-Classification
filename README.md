# Transfromational Machine Learning (TML)

**What is TML?** 
The vast majority of machine learning (ML) is predicated on modelling samples with intrinsic features. When there are numerous related ML issues (tasks), it is feasible to turn these intrinsic features into extrinsic features by training ML models on previous tasks and allowing them to make predictions for each instance of the new task, resulting in an unique representation. This method is defined  as transformational ML (TML). TML is strongly connected to transfer learning, multitask learning, and stacking, with which it is synergistic. TML may be used to enhance any nonlinear ML algorithm. TML was evaluated utilising the most significant nonlinear ML classes: random forests, gradient boosting machines, support vector machines, k-nearest neighbors, and neural networks. To guarantee the evaluation's generalizability and robustness, hundreds of ML problems were employed from three scientific domains: medication design, gene expression prediction, and ML method selection.

**Why TML is important?** 
In supervised machine learning, the machine learning system learns a model that can predict the labels of unseen instances by generalising from labelled examples. Typically, instances are represented by features that directly describe them. In situations where numerous related ML issues exist, it is reasonable to employ a different form of feature: predictions made about the instances by ML models trained on other problems (i.e. TML)  It was demonstrated that TML leads to enhanced predictions and comprehension when applied to scientific situations.

